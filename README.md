
# âœ… README.md

# Streaming Platform on Azure (Project 01) â€” Reusable 80/20 Framework

This repository contains a **production-style streaming data platform** built on Azure and Databricks, designed to be:

- **80% reusable platform engine**
- **20% configurable per client (tenant) and per event type (sensor/RFID)**

This platform supports both:

1. **Senior Data Engineering Portfolio Demonstration**
2. **Streaming Data Cleaning Business Foundation**

---

## ğŸ¯ Platform Goals

â€¢ Build production-grade streaming pipelines  
â€¢ Support multi-client (multi-tenant) onboarding  
â€¢ Support multiple sensor/event data types  
â€¢ Enforce strong data quality and schema validation  
â€¢ Enable fast onboarding through configuration instead of code changes  
â€¢ Demonstrate real-world DevOps and CI/CD architecture  

---

## ğŸ§± Technology Stack

| Component | Technology |
|----------|------------|
| Streaming Ingestion | Azure Event Hub |
| Processing | Azure Databricks Structured Streaming |
| Storage | Azure Data Lake Storage Gen2 |
| Table Format | Delta Lake |
| Orchestration | Databricks Multi-Task Jobs |
| CI/CD | Databricks Asset Bundles (Deployed) + GitHub Actions (Next Step) |

---

# ğŸ— Architecture Overview

Event Hub â†’ Bronze â†’ Silver â†’ Gold  

All data is stored in Delta Lake with partitioning:

```

tenant_id / event_type / ingest_date

```

The platform includes:

âœ” Config-driven onboarding  
âœ” Multi-tenant support  
âœ” DLQ (Dead Letter Queue) isolation  
âœ” Audit metrics tracking  
âœ” Managed identity secure compute  
âœ” CI/CD via Databricks Asset Bundles  

---

## ğŸ“¸ Platform Proof (Production Evidence)

### 1ï¸âƒ£ Job Orchestration (Bronze â†’ Silver â†’ Gold)

![Job Success](docs/screenshots/project01/01-job-success.png)

---

### 2ï¸âƒ£ Config-Driven Execution (Event Version Override)

YAML configuration enables onboarding new event versions without modifying core code.

![Runner Config Override](docs/screenshots/project01/02-runner-config-v2.png)

---

### 3ï¸âƒ£ DLQ â€“ Corrupt Event Isolation

Invalid JSON events are detected in Bronze and routed safely to Dead Letter Queue.

![DLQ Records](docs/screenshots/project01/03-dlq-table.png)

---

### 4ï¸âƒ£ Observability â€“ Audit Metrics

Each batch tracks:

- input_rows  
- output_rows  
- dlq_rows  
- latency metrics  
- job status  

![Audit Metrics](docs/screenshots/project01/04-audit-dlq-count.png)

---

### 5ï¸âƒ£ Gold Layer (Serving Output)

Aggregated device metrics written to:

```

gold/device_minute/

```

![Gold Output](docs/screenshots/project01/05-gold-output.png)

---

## ğŸ“¦ Universal Event Envelope (Contract-First Streaming)

All incoming streaming data follows a standardized envelope.

tenant_id  
site_id  
device_id  
device_type  
event_type  
event_id  
event_time_utc  
ingest_time_utc  
schema_version  
source_system  
payload  
attributes  

### Why This Matters

âœ” Standardizes ingestion across sensor types  
âœ” Enables reusable platform pipelines  
âœ” Supports multi-client separation  
âœ” Allows schema evolution  

---

## ğŸ—„ Storage Layout (ADLS Medallion Architecture)

raw  
bronze  
dlq  
silver  
gold  
checkpoints  
audit  

### Partition Strategy

```

tenant_id / event_type / ingest_date

```

This improves:

â€¢ Query performance  
â€¢ Storage cost efficiency  
â€¢ Replay/backfill capabilities  

---

## ğŸ“‚ Repository Structure

### 80% Reusable Platform Engine

```

src/
common/
bronze/
silver/
gold/

```

#### src/common
Shared utilities:
- Configuration loader
- Logging helpers
- Audit tracking
- Envelope validation

#### src/bronze
- Raw ingestion
- Envelope parsing
- DLQ routing
- Bronze table writes

#### src/silver
- Schema validation
- Data quality rules
- Enrichment hooks
- Clean standardized tables

#### src/gold
- Aggregations
- Merge/upsert serving tables
- Analytics-ready datasets

---

### 20% Configurable Surface

```

configs/
global/
tenants/

schemas/
event_types/

rules/
event_types/

```

#### configs/global
Platform default configuration.

#### configs/tenants
Per-client configuration files.

#### schemas/event_types
Payload schema definitions per event type.

#### rules/event_types
Data quality validation rules.

---

## ğŸ§© Multi-Client (Tenant) Support

Clients are separated using:

â€¢ `tenant_id` inside event envelope  
â€¢ Tenant-specific configuration  
â€¢ Tenant-based storage partitioning  

This enables:

âœ” New sensors for existing client  
âœ” New clients using same platform engine  

---

## ğŸš€ Onboarding Process

### Onboard New Event Type (Sensor / RFID / IoT Source)

1. Add schema file:
```

schemas/event_types/<event_type>.json

```

2. Add rule file:
```

rules/event_types/<event_type>.yml

```

3. Update tenant configuration:
```

configs/tenants/<tenant_id>/<environment>.yml

```

No core logic rewrite required.

---

### Onboard New Client

1. Create new folder:
```

configs/tenants/<new_tenant>/

```

2. Add:
- dev.yml
- stage.yml
- prod.yml

3. Deploy bundle:
```

databricks bundle deploy -t dev

```

Core platform remains unchanged.

---

## âš™ï¸ Runtime Execution (POC Mode)

Supports controlled test execution:

```

run_minutes = 5

```

Set to:

```

run_minutes = 0

```

for continuous production mode.

Pipeline execution order:

Bronze â†’ Silver â†’ Gold

---

## ğŸ“Š Observability & Monitoring

Audit tracking captures:

â€¢ Batch record counts  
â€¢ DLQ event counts  
â€¢ End-to-end latency  
â€¢ Job success/failure  
â€¢ Processing duration  

Audit table location:

```

audit/audit_pipeline_batches

```

---

## ğŸ”„ CI/CD

### Implemented

âœ” Databricks Asset Bundles  
âœ” Multi-environment targets (dev/stage/prod)  
âœ” Parameterized job execution  

### Next Step

â¡ GitHub Actions automated deployment  

---

## ğŸ“˜ Documentation

Located in `docs/` folder:

â€¢ runbook.md  
â€¢ onboarding_new_client.md  
â€¢ onboarding_new_event_type.md  
â€¢ platform_master_context.md  

---

## â­ Project Status

### Completed
âœ” Repository architecture  
âœ” Multi-tenant config structure  
âœ” Universal event contract  
âœ” Medallion storage layout  
âœ” Bronze/Silver/Gold streaming  
âœ” DLQ isolation with reason codes  
âœ” Audit metrics tracking  
âœ” Config-driven event onboarding  
âœ” CI/CD bundle deployment  

### Next Enhancements
â¡ GitHub Actions automation  
â¡ Replay/backfill framework  
â¡ Observability dashboards  

---

## ğŸ‘¨â€ğŸ’» Author

Ashraf Syed  
Senior Data Engineering Portfolio Project  
Streaming Data Cleaning Platform Initiative
```

---

